{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samkhur006/AI-project/blob/master/project_rupak_synapse3d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBdF4GG-9Il8",
        "outputId": "a3ec1ec4-319a-4415-848e-fca3031f7cb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting libauc==1.2.0\n",
            "  Downloading libauc-1.2.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from libauc==1.2.0) (8.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from libauc==1.2.0) (0.19.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from libauc==1.2.0) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from libauc==1.2.0) (1.5.3)\n",
            "Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.10/dist-packages (from libauc==1.2.0) (2.0.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from libauc==1.2.0) (1.22.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from libauc==1.2.0) (4.7.0.72)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2->libauc==1.2.0) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.2->libauc==1.2.0) (1.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.2->libauc==1.2.0) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.2->libauc==1.2.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2->libauc==1.2.0) (3.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.2->libauc==1.2.0) (3.12.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.2->libauc==1.2.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.2->libauc==1.2.0) (16.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->libauc==1.2.0) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->libauc==1.2.0) (2.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->libauc==1.2.0) (23.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->libauc==1.2.0) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->libauc==1.2.0) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->libauc==1.2.0) (2.25.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->libauc==1.2.0) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->libauc==1.2.0) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->libauc==1.2.0) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->libauc==1.2.0) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.2->libauc==1.2.0) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.2->libauc==1.2.0) (1.3.0)\n",
            "Installing collected packages: libauc\n",
            "Successfully installed libauc-1.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting medmnist\n",
            "  Downloading medmnist-2.2.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from medmnist) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.0.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist) (4.65.0)\n",
            "Collecting fire\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.15.1+cu118)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.5.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.19.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (2.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2022.7.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.4.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.10.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2023.4.12)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (23.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2.25.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (1.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (4.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2.0.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->medmnist) (16.0.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->medmnist) (3.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->medmnist) (2.27.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->medmnist) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (2.0.12)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->medmnist) (1.3.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116952 sha256=8223ea8e9b585fddb1f99b87da7bb196e3710e76e54dc952dfa6d19cacc471a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "Successfully built fire\n",
            "Installing collected packages: fire, medmnist\n",
            "Successfully installed fire-0.5.0 medmnist-2.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install libauc==1.2.0\n",
        "!pip install medmnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import libauc;\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from medmnist import SynapseMNIST3D\n",
        "import random\n",
        "import scipy\n",
        "from scipy import ndimage\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "from scipy.ndimage import zoom\n",
        "\n",
        "\n",
        "from libauc.models import resnet18\n",
        "from libauc.losses import AUCMLoss, CrossEntropyLoss\n",
        "from libauc.optimizers import PESG, Adam\n",
        "from libauc.utils import ImbalancedDataGenerator\n",
        "from libauc.sampler import DualSampler  # data resampling (for binary class)\n",
        "from libauc.metrics import auc_roc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import random\n",
        "import scipy\n",
        "from scipy.ndimage import rotate\n",
        "from scipy import ndimage\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "from scipy.ndimage import zoom\n",
        "\n",
        "import torch \n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "SEED=123"
      ],
      "metadata": {
        "id": "gbqX-H869ab2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f732bd38-703d-4925-81e8-e5707a84a058"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-dc4e5e113929>:8: DeprecationWarning: Please use `gaussian_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
            "  from scipy.ndimage.filters import gaussian_filter\n",
            "<ipython-input-2-dc4e5e113929>:24: DeprecationWarning: Please use `gaussian_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
            "  from scipy.ndimage.filters import gaussian_filter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Adapted from kuangliu/pytorch-cifar .\n",
        "'''\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        # self.bn1 = nn.GroupNorm(num_groups=2, num_channels=planes)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        # self.bn2 = nn.GroupNorm(num_groups=2, num_channels=planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "                # nn.GroupNorm(num_groups=2, num_channels=self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        # self.bn1 = nn.GroupNorm(num_groups=2, num_channels=planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        # self.bn2 = nn.GroupNorm(num_groups=2, num_channels=planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "        # self.bn3 = nn.GroupNorm(num_groups=2, num_channels=self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "                # nn.GroupNorm(num_groups=2, num_channels=self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, in_channels=1, num_classes=2):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        # self.bn1 = nn.GroupNorm(num_groups=2, num_channels=64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        # out = F.avg_pool2d(out, 4)\n",
        "        # out = F.adaptive_avg_pool3d(out, output_size=4)\n",
        "        out = self.avgpool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18(in_channels, num_classes):\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], in_channels=in_channels, num_classes=num_classes)\n",
        "\n",
        "\n",
        "def ResNet50(in_channels, num_classes):\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3], in_channels=in_channels, num_classes=num_classes)"
      ],
      "metadata": {
        "id": "IPvcQiVZ1s19"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_npz=SynapseMNIST3D(split=\"train\", download=True)\n",
        "val_npz=SynapseMNIST3D(split=\"val\", download=True)\n",
        "test_npz=SynapseMNIST3D(split=\"test\", download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS9RSC169wC6",
        "outputId": "ffd788cb-ef8b-4743-8529-c2cfa9af7b12"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://zenodo.org/record/6496656/files/synapsemnist3d.npz?download=1 to /root/.medmnist/synapsemnist3d.npz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38034583/38034583 [01:10<00:00, 539288.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: /root/.medmnist/synapsemnist3d.npz\n",
            "Using downloaded and verified file: /root/.medmnist/synapsemnist3d.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gaussian_blur_3d(img):\n",
        "    random.seed(SEED)\n",
        "    sigma = random.uniform(0.1,0.9)\n",
        "    blurred = gaussian_filter(img, sigma=sigma)\n",
        "    return blurred"
      ],
      "metadata": {
        "id": "DIur0t5KBGnI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def x_flip(img):\n",
        "    random.seed(SEED)\n",
        "    flipped = img[:, :, ::-1]\n",
        "    return flipped"
      ],
      "metadata": {
        "id": "M6Etf16IBNVx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def y_flip(img):\n",
        "    random.seed(SEED)\n",
        "    flipped = img[:, ::-1, :]\n",
        "    return flipped"
      ],
      "metadata": {
        "id": "miD1eOA8BVoZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def zoom_xy(img, min_zoom, max_zoom):\n",
        "    random.seed(SEED)\n",
        "    zoom_factor = random.uniform(min_zoom, max_zoom)\n",
        "    h, w = img.shape[0], img.shape[1]\n",
        "\n",
        "    # For multichannel images we don't want to apply the zoom factor to the RGB\n",
        "    # dimension, so instead we create a tuple of zoom factors, one per array\n",
        "    # dimension, with 1's for any trailing dimensions after the width and height.\n",
        "    zoom_tuple = (1, zoom_factor, zoom_factor)\n",
        "\n",
        "    # Zooming out\n",
        "    if zoom_factor < 1:\n",
        "\n",
        "        # Bounding box of the zoomed-out image within the output array\n",
        "        zh = int(np.round(h * zoom_factor))\n",
        "        zw = int(np.round(w * zoom_factor))\n",
        "        top = (h - zh) // 2\n",
        "        left = (w - zw) // 2\n",
        "\n",
        "        # Zero-padding\n",
        "        out = np.zeros_like(img)\n",
        "        zoomed_img = zoom(img, zoom_tuple, order=0)\n",
        "        #print(f\"zoomed shape: {zoomed_img.shape}\")\n",
        "        #print(f\"out shape:{out.shape}\")\n",
        "        #print(f\"w:{w},h:{h},l:{left},t:{top},zw:{zw}, zh:{zh}\")\n",
        "        out[:, top:top+zh, left:left+zw] = zoomed_img\n",
        "\n",
        "    # Zooming in\n",
        "    elif zoom_factor > 1:\n",
        "\n",
        "        # Bounding box of the zoomed-in region within the input array\n",
        "        zh = int(np.ceil(h / zoom_factor))\n",
        "        zw = int(np.ceil(w / zoom_factor))\n",
        "        top = (h - zh) // 2\n",
        "        left = (w - zw) // 2\n",
        "\n",
        "        #out_template = np.zeros_like(img)\n",
        "        out = zoom(img[:, top:top+zh, left:left+zw], zoom_tuple, order=0)\n",
        "        #print(f\"out shape:{out.shape}\")\n",
        "        #print(f\"w:{w},h:{h},l:{left},t:{top},zw:{zw}, zh:{zh}\")\n",
        "\n",
        "        # `out` might still be slightly larger than `img` due to rounding, so\n",
        "        # trim off any extra pixels at the edges\n",
        "        trim_top = ((out.shape[1] - h) // 2)\n",
        "        trim_left = ((out.shape[2] - w) // 2)\n",
        "        #print(f\"out shape before:{out.shape}\")\n",
        "        out = out[:, trim_top:trim_top+h, trim_left:trim_left+w]\n",
        "        #print(f\"out shape after:{out.shape}\")\n",
        "        #print(f\"w:{w},h:{h},l:{left},trimtop:{trim_top},trimleft:{trim_left}\")\n",
        "\n",
        "    # If zoom_factor == 1, just return the input array\n",
        "    else:\n",
        "        out = img\n",
        "    #print(out.shape)\n",
        "    return out"
      ],
      "metadata": {
        "id": "zU1FgZEGBhdP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_rotation_3d(img, min_angle, max_angle):\n",
        "    \"\"\" Randomly rotate an image by a random angle (-max_angle, max_angle).\n",
        "\n",
        "    Arguments:\n",
        "    max_angle: `float`. The maximum rotation angle.\n",
        "\n",
        "    Returns:\n",
        "    rotated 3D image\n",
        "    \"\"\"\n",
        "    random.seed(SEED)\n",
        "    img_rot = np.zeros(img.shape)\n",
        "    angle = random.uniform(min_angle, max_angle)\n",
        "    if random.randint(1,100) > 50:\n",
        "        #in half the cases, rotate left. in other half, rotate right.\n",
        "        angle *= -1\n",
        "        # Following lines would rotate on z and y axis as well, but not using them in this kernel\n",
        "#        # rotate along z-axis\n",
        "#        image2 = scipy.ndimage.interpolation.rotate(image1, angle, mode='nearest', axes=(0, 1), reshape=False)\n",
        "#        # rotate along y-axis\n",
        "#        image3 = scipy.ndimage.interpolation.rotate(image2, angle, mode='nearest', axes=(0, 2), reshape=False)\n",
        "\n",
        "    # rotate along x-axis\n",
        "    img_rot = scipy.ndimage.interpolation.rotate(img, angle, mode='nearest', axes=(1, 2), reshape=False)\n",
        "    return img_rot.reshape(img.shape)"
      ],
      "metadata": {
        "id": "ni9_kZPEy3ET"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def img_augment_3d(X_train,y_train):\n",
        "      my_img=X_train\n",
        "      my_label=y_train\n",
        "      # for i in range(0,X_train.shape[0]):\n",
        "      #   img=X_train[i]\n",
        "      #   img1 = gaussian_blur_3d(img)\n",
        "      #   my_img=np.append(my_img,np.expand_dims(img1,axis=0),axis=0)\n",
        "      # my_label=np.append(my_label,y_train,axis=0)\n",
        "      print(\"done\")\n",
        "      for i in range(0,X_train.shape[0]):\n",
        "        img=X_train[i]\n",
        "        img1 = x_flip(img)\n",
        "        my_img=np.append(my_img,np.expand_dims(img1,axis=0),axis=0)\n",
        "      my_label=np.append(my_label,y_train,axis=0)\n",
        "      print(\"done\")\n",
        "      for i in range(0,X_train.shape[0]):\n",
        "        img=X_train[i]\n",
        "        img1 = y_flip(img)\n",
        "        my_img=np.append(my_img,np.expand_dims(img1,axis=0),axis=0)\n",
        "      my_label=np.append(my_label,y_train,axis=0)\n",
        "\n",
        "      for i in range(0,X_train.shape[0]):\n",
        "        img=X_train[i]\n",
        "        img1 = random_rotation_3d(img, 1, 10)\n",
        "        my_img=np.append(my_img,np.expand_dims(img1,axis=0),axis=0)\n",
        "      my_label=np.append(my_label,y_train,axis=0)\n",
        "\n",
        "      for i in range(0,X_train.shape[0]):\n",
        "        img=X_train[i]\n",
        "        img1 = zoom_xy(img, 0.9, 1.1)\n",
        "        my_img=np.append(my_img,np.expand_dims(img1,axis=0),axis=0)\n",
        "      my_label=np.append(my_label,y_train,axis=0)\n",
        "    \n",
        "      return my_img,my_label"
      ],
      "metadata": {
        "id": "JMM1rAUoC2fb"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=train_npz.imgs\n",
        "y_train=train_npz.labels\n",
        "\n",
        "X_val=val_npz.imgs\n",
        "y_val=val_npz.labels\n",
        "\n",
        "X_test=test_npz.imgs\n",
        "y_test=test_npz.labels"
      ],
      "metadata": {
        "id": "EhN1XJogOHiA"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,y_train=img_augment_3d(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4qXoLuhJP8-",
        "outputId": "d82407a8-3bb6-4021-d98d-9aaf33fe4d96"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape,y_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_r8cXpFMsFK",
        "outputId": "5cc7990c-b851-4e1c-80d8-b71d9b9b330b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6150, 28, 28, 28) (6150, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VjbjEHBL9zDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-4BvvFXTk6m",
        "outputId": "056ef15b-fa05-4336-c171-83aad4683353"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6150, 28, 28, 28)\n",
            "(6150, 1)\n",
            "(177, 28, 28, 28)\n",
            "(177, 1)\n",
            "(352, 28, 28, 28)\n",
            "(352, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, images, targets, image_size=28, crop_size=26, mode='train'):\n",
        "       self.images = images.astype(np.uint8)\n",
        "       self.targets = targets\n",
        "       self.mode = mode\n",
        "       self.transform_train = transforms.Compose([                                               \n",
        "                              transforms.ToTensor(),\n",
        "                              transforms.RandomRotation(10),\n",
        "                              transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
        "                              # transforms.RandomCrop((crop_size, crop_size, crop_), padding=None),\n",
        "                              transforms.RandomHorizontalFlip(),\n",
        "                              transforms.RandomVerticalFlip(p=0.2),\n",
        "\n",
        "                              # transforms.Resize((image_size, image_size, image_size)),\n",
        "                              ])\n",
        "       self.transform_test = transforms.Compose([\n",
        "                             transforms.ToTensor(),\n",
        "                            #  transforms.Resize((image_size, image_size, image_size)),\n",
        "                              ])\n",
        "       \n",
        "       # for loss function\n",
        "       self.pos_indices = np.flatnonzero(targets==1)\n",
        "       self.pos_index_map = {}\n",
        "       for i, idx in enumerate(self.pos_indices):\n",
        "           self.pos_index_map[idx] = i\n",
        "\n",
        "    def __len__(self):\n",
        "        # print(len(self.images))\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        target = self.targets[idx]\n",
        "        if self.mode == 'train':\n",
        "            idx = self.pos_index_map[idx] if idx in self.pos_indices else -1\n",
        "            image = self.transform_train(image)\n",
        "        else:\n",
        "            image = self.transform_test(image)\n",
        "        return image, target, int(idx)\n",
        "\n"
      ],
      "metadata": {
        "id": "FXKk7jbUaK_k"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_all_seeds(SEED):\n",
        "    # REPRODUCIBILITY\n",
        "    torch.manual_seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "paXm1nfPBE_d"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# HyperParameters\n",
        "\n",
        "batch_size = 64\n",
        "total_epochs = 40\n",
        "decay_epochs = [50, 75]\n",
        "\n",
        "lr = 0.1\n",
        "margin = 1.0\n",
        "epoch_decay = 0.003 # refers gamma in the paper\n",
        "weight_decay = 0.0001\n",
        "\n",
        "# oversampling minority class, you can tune it in (0, 0.5]\n",
        "# e.g., sampling_rate=0.2 is that num of positive samples in mini-batch is sampling_rate*batch_size=13\n",
        "sampling_rate = 0.2\n"
      ],
      "metadata": {
        "id": "ebSFQuU9BIoC"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imratio = 0.5\n",
        "generator = ImbalancedDataGenerator(shuffle=True, verbose=True, random_seed=0)\n",
        "\n",
        "(train_images, train_labels) = generator.transform(X_train, y_train, imratio=imratio)\n",
        "(eval_images, eval_labels) = generator.transform(X_val, y_val, imratio=imratio)\n",
        "(test_images, test_labels) = generator.transform(X_test, y_test, imratio=0.5) \n",
        "\n",
        "# print((train_images.shape))\n",
        "# print((eval_images.shape))\n",
        "# print((test_images.shape))\n",
        "trainSet = ImageDataset(train_images, train_labels)\n",
        "evalSet = ImageDataset(eval_images, eval_labels)\n",
        "testSet = ImageDataset(test_images, test_labels, mode='test')\n",
        "\n",
        "sampler = DualSampler(trainSet, batch_size, sampling_rate=sampling_rate)\n",
        "trainloader = torch.utils.data.DataLoader(trainSet, batch_size=batch_size,  sampler=sampler,  shuffle=False,  num_workers=1)\n",
        "evalloader = torch.utils.data.DataLoader(evalSet, batch_size=batch_size,  shuffle=False,  num_workers=1)\n",
        "testloader = torch.utils.data.DataLoader(testSet , batch_size=batch_size, shuffle=False, num_workers=1)"
      ],
      "metadata": {
        "id": "-MhjgR2SEmgE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a744e83f-9aff-4ac3-bf3f-d191940119e4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#SAMPLES: [6150], POS:NEG: [4495 : 1655], POS RATIO: 0.7309\n",
            "#SAMPLES: [177], POS:NEG: [129 : 48], POS RATIO: 0.7288\n",
            "#SAMPLES: [352], POS:NEG: [257 : 95], POS RATIO: 0.7301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDMIvX8s9WTz",
        "outputId": "6ed2bd08-c540-429e-9fae-10dc81179b53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7380, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGyE6xjzZbOr",
        "outputId": "0273af11-314e-43c2-c4dd-f4d33212be67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5394])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "set_all_seeds(SEED)\n",
        "# model = resnet18(pretrained=False, num_classes=1, last_activation=None) \n",
        "model = ResNet18(in_channels = 28, num_classes= 2)\n",
        "\n",
        "model = model.cuda()\n",
        "\n",
        "# You can also pass Loss.a, Loss.b, Loss.alpha to optimizer (for old version users)\n",
        "loss_fn = AUCMLoss()\n",
        "lr = 0.1\n",
        "optimizer = PESG(model, \n",
        "                 loss_fn=loss_fn,\n",
        "                 lr=lr, \n",
        "                 momentum=0.5,\n",
        "                 margin=margin,\n",
        "                 epoch_decay=epoch_decay, \n",
        "                 weight_decay=weight_decay)\n",
        "scheduler1 =  ReduceLROnPlateau(optimizer, 'min', patience=2, factor = 0.05)\n",
        "# loss_fn = CrossEntropyLoss()\n",
        "# optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "# model"
      ],
      "metadata": {
        "id": "kLN4Unkc9_A0"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(evalloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5cuRVkg7H5P",
        "outputId": "6b4c6c19-2b49-452f-a96a-c725b8439b55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7f2af786b6d0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print ('Start Training')\n",
        "print ('-'*30)\n",
        "# ckpt =  torch.load(\"Epoch_scheduler: 10.pt\")\n",
        "# model.load_state_dict(ckpt)\n",
        "train_log = []\n",
        "best_train_auc=0\n",
        "test_log = []\n",
        "for epoch in range(total_epochs):\n",
        "     if epoch in decay_epochs:\n",
        "         optimizer.update_regularizer(decay_factor=10) # decrease learning rate by 10x & update regularizer\n",
        "   \n",
        "     train_loss = []\n",
        "     model.train()    \n",
        "     for data, targets, _ in trainloader:\n",
        "         data, targets  = data.cuda(), targets.cuda()\n",
        "         y_pred = model(data)\n",
        "         y_pred = torch.sigmoid(y_pred)\n",
        "         loss = loss_fn(y_pred, targets)\n",
        "         optimizer.zero_grad()\n",
        "         loss.backward()\n",
        "         optimizer.step()\n",
        "         train_loss.append(loss.item())\n",
        "     if epoch % 5 == 0:\n",
        "       torch.save(model.state_dict(), \"Epoch: {}.pt\".format(epoch))\n",
        "       print(\"Saving model for epoch number: {}\".format(epoch))\n",
        "     # evaluation on train & test sets\n",
        "     \n",
        "     train_pred_list = []\n",
        "     train_true_list = []\n",
        "     model.eval()\n",
        "\n",
        "     for train_data, train_targets,_ in evalloader:\n",
        "         train_data = train_data.cuda()\n",
        "         train_pred = model(train_data)\n",
        "         train_pred_list.append(train_pred.cpu().detach().numpy())\n",
        "         train_true_list.append(train_targets.numpy())\n",
        "     train_true = np.concatenate(train_true_list)\n",
        "     train_pred = np.concatenate(train_pred_list)\n",
        "     train_auc=auc_roc_score(train_true, train_pred)[0]\n",
        "\n",
        "     train_loss = np.mean(train_loss)\n",
        "     scheduler1.step(train_loss)\n",
        "     if best_train_auc < train_auc:\n",
        "       best_train_auc=train_auc\n",
        "       torch.save(model.state_dict(), 'synapse.pt')\n",
        "     \n",
        "     test_pred_list = []\n",
        "     test_true_list = [] \n",
        "     for test_data, test_targets,_ in testloader:\n",
        "         test_data = test_data.cuda()\n",
        "         test_pred = model(test_data)\n",
        "         test_pred_list.append(test_pred.cpu().detach().numpy())\n",
        "         test_true_list.append(test_targets.numpy())\n",
        "     test_true = np.concatenate(test_true_list)\n",
        "     test_pred = np.concatenate(test_pred_list)\n",
        "     val_auc =  auc_roc_score(test_true, test_pred)[0]\n",
        "     #val_auc =  auc_roc_score(test_true[:,0], test_pred[:,0]) \n",
        " \n",
        "     # print results\n",
        "     print(\"epoch: %s, train_loss: %.4f, val_auc: %.4f, best_val_auc: %.4f, test_auc: %.4f, lr: %.4f\"%(epoch, train_loss, train_auc, best_train_auc, val_auc, optimizer.lr )) \n",
        "     train_log.append(train_auc) \n",
        "     test_log.append(val_auc)  "
      ],
      "metadata": {
        "id": "5X9GLYIP-8Z7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c79f8542-0568-4cc5-d0e0-8db19cae3a88"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Training\n",
            "------------------------------\n",
            "Saving model for epoch number: 0\n",
            "epoch: 0, train_loss: 0.0033, val_auc: 0.7787, best_val_auc: 0.7787, test_auc: 0.8249, lr: 0.0050\n",
            "epoch: 1, train_loss: 0.0031, val_auc: 0.7907, best_val_auc: 0.7907, test_auc: 0.8234, lr: 0.0050\n",
            "epoch: 2, train_loss: 0.0031, val_auc: 0.7773, best_val_auc: 0.7907, test_auc: 0.8222, lr: 0.0050\n",
            "epoch: 3, train_loss: 0.0032, val_auc: 0.7786, best_val_auc: 0.7907, test_auc: 0.8285, lr: 0.0050\n",
            "epoch: 4, train_loss: 0.0031, val_auc: 0.7663, best_val_auc: 0.7907, test_auc: 0.8239, lr: 0.0050\n",
            "Saving model for epoch number: 5\n",
            "epoch: 5, train_loss: 0.0031, val_auc: 0.7951, best_val_auc: 0.7951, test_auc: 0.8267, lr: 0.0050\n",
            "epoch: 6, train_loss: 0.0030, val_auc: 0.7860, best_val_auc: 0.7951, test_auc: 0.8272, lr: 0.0003\n",
            "epoch: 7, train_loss: 0.0031, val_auc: 0.8043, best_val_auc: 0.8043, test_auc: 0.8276, lr: 0.0003\n",
            "epoch: 8, train_loss: 0.0030, val_auc: 0.7573, best_val_auc: 0.8043, test_auc: 0.8274, lr: 0.0003\n",
            "epoch: 9, train_loss: 0.0032, val_auc: 0.7818, best_val_auc: 0.8043, test_auc: 0.8256, lr: 0.0003\n",
            "Saving model for epoch number: 10\n",
            "epoch: 10, train_loss: 0.0030, val_auc: 0.7873, best_val_auc: 0.8043, test_auc: 0.8277, lr: 0.0003\n",
            "epoch: 11, train_loss: 0.0031, val_auc: 0.7686, best_val_auc: 0.8043, test_auc: 0.8280, lr: 0.0003\n",
            "epoch: 12, train_loss: 0.0030, val_auc: 0.7865, best_val_auc: 0.8043, test_auc: 0.8270, lr: 0.0003\n",
            "epoch: 13, train_loss: 0.0028, val_auc: 0.7917, best_val_auc: 0.8043, test_auc: 0.8275, lr: 0.0003\n",
            "epoch: 14, train_loss: 0.0031, val_auc: 0.7647, best_val_auc: 0.8043, test_auc: 0.8268, lr: 0.0003\n",
            "Saving model for epoch number: 15\n",
            "epoch: 15, train_loss: 0.0031, val_auc: 0.7825, best_val_auc: 0.8043, test_auc: 0.8281, lr: 0.0003\n",
            "epoch: 16, train_loss: 0.0032, val_auc: 0.7847, best_val_auc: 0.8043, test_auc: 0.8281, lr: 0.0003\n",
            "epoch: 17, train_loss: 0.0031, val_auc: 0.7757, best_val_auc: 0.8043, test_auc: 0.8272, lr: 0.0000\n",
            "epoch: 18, train_loss: 0.0029, val_auc: 0.7713, best_val_auc: 0.8043, test_auc: 0.8268, lr: 0.0000\n",
            "epoch: 19, train_loss: 0.0029, val_auc: 0.7812, best_val_auc: 0.8043, test_auc: 0.8271, lr: 0.0000\n",
            "Saving model for epoch number: 20\n",
            "epoch: 20, train_loss: 0.0032, val_auc: 0.7799, best_val_auc: 0.8043, test_auc: 0.8276, lr: 0.0000\n",
            "epoch: 21, train_loss: 0.0031, val_auc: 0.7747, best_val_auc: 0.8043, test_auc: 0.8279, lr: 0.0000\n",
            "epoch: 22, train_loss: 0.0031, val_auc: 0.8099, best_val_auc: 0.8099, test_auc: 0.8274, lr: 0.0000\n",
            "epoch: 23, train_loss: 0.0030, val_auc: 0.7658, best_val_auc: 0.8099, test_auc: 0.8267, lr: 0.0000\n",
            "epoch: 24, train_loss: 0.0032, val_auc: 0.7852, best_val_auc: 0.8099, test_auc: 0.8279, lr: 0.0000\n",
            "Saving model for epoch number: 25\n",
            "epoch: 25, train_loss: 0.0030, val_auc: 0.7941, best_val_auc: 0.8099, test_auc: 0.8282, lr: 0.0000\n",
            "epoch: 26, train_loss: 0.0030, val_auc: 0.7671, best_val_auc: 0.8099, test_auc: 0.8272, lr: 0.0000\n",
            "epoch: 27, train_loss: 0.0030, val_auc: 0.7611, best_val_auc: 0.8099, test_auc: 0.8279, lr: 0.0000\n",
            "epoch: 28, train_loss: 0.0031, val_auc: 0.7744, best_val_auc: 0.8099, test_auc: 0.8271, lr: 0.0000\n",
            "epoch: 29, train_loss: 0.0032, val_auc: 0.8002, best_val_auc: 0.8099, test_auc: 0.8274, lr: 0.0000\n",
            "Saving model for epoch number: 30\n",
            "epoch: 30, train_loss: 0.0030, val_auc: 0.7749, best_val_auc: 0.8099, test_auc: 0.8274, lr: 0.0000\n",
            "epoch: 31, train_loss: 0.0030, val_auc: 0.7749, best_val_auc: 0.8099, test_auc: 0.8273, lr: 0.0000\n",
            "epoch: 32, train_loss: 0.0029, val_auc: 0.7863, best_val_auc: 0.8099, test_auc: 0.8272, lr: 0.0000\n",
            "epoch: 33, train_loss: 0.0030, val_auc: 0.7951, best_val_auc: 0.8099, test_auc: 0.8286, lr: 0.0000\n",
            "epoch: 34, train_loss: 0.0031, val_auc: 0.7700, best_val_auc: 0.8099, test_auc: 0.8277, lr: 0.0000\n",
            "Saving model for epoch number: 35\n",
            "epoch: 35, train_loss: 0.0030, val_auc: 0.7508, best_val_auc: 0.8099, test_auc: 0.8271, lr: 0.0000\n",
            "epoch: 36, train_loss: 0.0030, val_auc: 0.7791, best_val_auc: 0.8099, test_auc: 0.8273, lr: 0.0000\n",
            "epoch: 37, train_loss: 0.0032, val_auc: 0.7641, best_val_auc: 0.8099, test_auc: 0.8286, lr: 0.0000\n",
            "epoch: 38, train_loss: 0.0030, val_auc: 0.7980, best_val_auc: 0.8099, test_auc: 0.8271, lr: 0.0000\n",
            "epoch: 39, train_loss: 0.0032, val_auc: 0.7892, best_val_auc: 0.8099, test_auc: 0.8266, lr: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "ckpt =  torch.load(\"synapse.pt\")\n",
        "model.load_state_dict(ckpt)\n",
        "model.eval()\n",
        "best_test_auc = 0\n",
        "with torch.no_grad():    \n",
        "  test_pred = []\n",
        "  test_true = [] \n",
        "  for jdx, (data, targets, _) in enumerate(testloader):\n",
        "      test_data, test_labels = data, targets\n",
        "      test_data = test_data.cuda()\n",
        "      y_pred = model(test_data)\n",
        "      y_pred = torch.sigmoid(y_pred)\n",
        "      test_pred.append(y_pred.cpu().detach().numpy())\n",
        "      test_true.append(test_labels.numpy())\n",
        "\n",
        "  test_true = np.concatenate(test_true)\n",
        "  test_pred = np.concatenate(test_pred)\n",
        "  test_auc_mean = auc_roc_score(test_true, test_pred)[0]\n",
        "  model.train()\n",
        "\n",
        "\n",
        "  print ('Test result   ::::::::::  Test_AUC=%.4f'%( test_auc_mean))\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jh8qwFg-iz6y",
        "outputId": "c5052996-bbc8-4313-ae34-7c2cb9c75f92"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test result   ::::::::::  Test_AUC=0.8274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "4*6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pLm-DPfqVhI",
        "outputId": "156a4a20-8a5c-4d90-d187-8e3260ba1e79"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bY9sT5_6qWws"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}